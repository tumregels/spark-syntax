
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Section 2.10 - Spark Functions aren't Enough, I Need my Own! Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="Section 2.11  - Unionizing Multiple Dataframes.html" />
    
    
    <link rel="prev" href="Section 2.9 - Filling in Null Values.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    README
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Chapter 1 - Basics
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../Chapter 1 - Basics/Section 1 - Useful Material.html">
            
                <a href="../Chapter 1 - Basics/Section 1 - Useful Material.html">
            
                    
                    Section 1 - Useful Material
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../Chapter 1 - Basics/Section 2 - Creating your First Data Object.html">
            
                <a href="../Chapter 1 - Basics/Section 2 - Creating your First Data Object.html">
            
                    
                    Section 2 - Creating your First Data Object
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../Chapter 1 - Basics/Section 3 - Reading your First Dataset.html">
            
                <a href="../Chapter 1 - Basics/Section 3 - Reading your First Dataset.html">
            
                    
                    Section 3 - Reading your First Dataset
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../Chapter 1 - Basics/Section 4 - More Comfortable with SQL.html">
            
                <a href="../Chapter 1 - Basics/Section 4 - More Comfortable with SQL.html">
            
                    
                    Section 4 - More Comfortable with SQL
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Chapter 2 - Exploring the Spark APIs
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="Section 1.1 - Struct Types.html">
            
                <a href="Section 1.1 - Struct Types.html">
            
                    
                    Section 1.1 - Struct Types
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="Section 1.2 - Arrays and Lists.html">
            
                <a href="Section 1.2 - Arrays and Lists.html">
            
                    
                    Section 1.2 - Arrays and Lists
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="Section 1.3 - Maps and Dictionaries.html">
            
                <a href="Section 1.3 - Maps and Dictionaries.html">
            
                    
                    Section 1.3 - Maps and Dictionaries
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="Section 1.4 - Decimals and Why did my Decimals Overflow.html">
            
                <a href="Section 1.4 - Decimals and Why did my Decimals Overflow.html">
            
                    
                    Section 1.4 - Decimals and Why did my Decimals Overflow
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="Section 2 - Performing your First Transformations.html">
            
                <a href="Section 2 - Performing your First Transformations.html">
            
                    
                    Section 2 - Performing your First Transformations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="Section 2.1 - Looking at Your Data.html">
            
                <a href="Section 2.1 - Looking at Your Data.html">
            
                    
                    Section 2.1 - Looking at Your Data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="Section 2.2 - Selecting a Subset of Columns.html">
            
                <a href="Section 2.2 - Selecting a Subset of Columns.html">
            
                    
                    Section 2.2 - Selecting a Subset of Columns
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="Section 2.3 - Creating New Columns and Transforming Data.html">
            
                <a href="Section 2.3 - Creating New Columns and Transforming Data.html">
            
                    
                    Section 2.3 - Creating New Columns and Transforming Data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="Section 2.4 - Constant Values and Column Expressions.html">
            
                <a href="Section 2.4 - Constant Values and Column Expressions.html">
            
                    
                    Section 2.4 - Constant Values and Column Expressions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.10" data-path="Section 2.5 - Casting Columns to Different Type.html">
            
                <a href="Section 2.5 - Casting Columns to Different Type.html">
            
                    
                    Section 2.5 - Casting Columns to Different Type
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.11" data-path="Section 2.6 - Filtering Data.html">
            
                <a href="Section 2.6 - Filtering Data.html">
            
                    
                    Section 2.6 - Filtering Data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.12" data-path="Section 2.7 - Equality Statements in Spark and Comparison with Nulls.html">
            
                <a href="Section 2.7 - Equality Statements in Spark and Comparison with Nulls.html">
            
                    
                    Section 2.7 - Equality Statements in Spark and Comparison with Nulls
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.13" data-path="Section 2.8 - Case Statements.html">
            
                <a href="Section 2.8 - Case Statements.html">
            
                    
                    Section 2.8 - Case Statements
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.14" data-path="Section 2.9 - Filling in Null Values.html">
            
                <a href="Section 2.9 - Filling in Null Values.html">
            
                    
                    Section 2.9 - Filling in Null Values
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.15" data-path="Section 2.10 - Spark Functions aren't Enough, I Need my Own!.html">
            
                <a href="Section 2.10 - Spark Functions aren't Enough, I Need my Own!.html">
            
                    
                    Section 2.10 - Spark Functions aren't Enough, I Need my Own!
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.16" data-path="Section 2.11  - Unionizing Multiple Dataframes.html">
            
                <a href="Section 2.11  - Unionizing Multiple Dataframes.html">
            
                    
                    Section 2.11  - Unionizing Multiple Dataframes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.17" data-path="Section 2.12 - Performing Joins <clean one>.html">
            
                <a href="Section 2.12 - Performing Joins <clean one>.html">
            
                    
                    Section 2.12 - Performing Joins 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.18" data-path="Section 3.1 - One to Many Rows.html">
            
                <a href="Section 3.1 - One to Many Rows.html">
            
                    
                    Section 3.1 - One to Many Rows
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.19" data-path="Section 3.2 - Range Join Conditions <WIP>.html">
            
                <a href="Section 3.2 - Range Join Conditions <WIP>.html">
            
                    
                    Section 3.2 - Range Join Conditions 
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Chapter 3 - Aggregates
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../Chapter 3 - Aggregates/Section 1 - Clean Aggregations.html">
            
                <a href="../Chapter 3 - Aggregates/Section 1 - Clean Aggregations.html">
            
                    
                    Section 1 - Clean Aggregations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../Chapter 3 - Aggregates/Section 2 - Non Deterministic Ordering for GroupBys.html">
            
                <a href="../Chapter 3 - Aggregates/Section 2 - Non Deterministic Ordering for GroupBys.html">
            
                    
                    Section 2 - Non Deterministic Ordering for GroupBys
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    Chapter 4 - Window Objects
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../Chapter 4 - Window Objects/Section 1 - Default Behaviour of a Window Object.html">
            
                <a href="../Chapter 4 - Window Objects/Section 1 - Default Behaviour of a Window Object.html">
            
                    
                    Section 1 - Default Behaviour of a Window Object
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../Chapter 4 - Window Objects/Section 2 - Ordering High Frequency Data with a Window Object.html">
            
                <a href="../Chapter 4 - Window Objects/Section 2 - Ordering High Frequency Data with a Window Object.html">
            
                    
                    Section 2 - Ordering High Frequency Data with a Window Object
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    Chapter 6 - Tuning & Spark Parameters
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../Chapter 6 - Tuning & Spark Parameters/Section 1.1 - Understanding how Spark Works.html">
            
                <a href="../Chapter 6 - Tuning & Spark Parameters/Section 1.1 - Understanding how Spark Works.html">
            
                    
                    Section 1.1 - Understanding how Spark Works
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    Chapter 7 - High Performance Code
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../Chapter 7 - High Performance Code/Section 1.1 - Filter Pushdown.html">
            
                <a href="../Chapter 7 - High Performance Code/Section 1.1 - Filter Pushdown.html">
            
                    
                    Section 1.1 - Filter Pushdown
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../Chapter 7 - High Performance Code/Section 1.2 - Joins on Skewed Data <Null Keys>.html">
            
                <a href="../Chapter 7 - High Performance Code/Section 1.2 - Joins on Skewed Data <Null Keys>.html">
            
                    
                    Section 1.2 - Joins on Skewed Data 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../Chapter 7 - High Performance Code/Section 1.3 - Joins on Skewed Data <High Frequency Keys I>.html">
            
                <a href="../Chapter 7 - High Performance Code/Section 1.3 - Joins on Skewed Data <High Frequency Keys I>.html">
            
                    
                    Section 1.3 - Joins on Skewed Data 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="../Chapter 7 - High Performance Code/Section 1.4 - Joins on Skewed Data <High Frequency Keys II> <WIP>.html">
            
                <a href="../Chapter 7 - High Performance Code/Section 1.4 - Joins on Skewed Data <High Frequency Keys II> <WIP>.html">
            
                    
                    Section 1.4 - Joins on Skewed Data  
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Section 2.10 - Spark Functions aren't Enough, I Need my Own!</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h3 id="library-imports">Library Imports</h3>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession
<span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> types <span class="hljs-keyword">as</span> T

<span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> functions <span class="hljs-keyword">as</span> F

<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">from</span> decimal <span class="hljs-keyword">import</span> Decimal
</code></pre>
<h3 id="template">Template</h3>
<pre><code class="lang-python">spark = (
    SparkSession.builder
    .master(<span class="hljs-string">&quot;local&quot;</span>)
    .appName(<span class="hljs-string">&quot;Section 2.10 - Spark Functions aren&apos;t Enough, I Need my Own!&quot;</span>)
    .config(<span class="hljs-string">&quot;spark.some.config.option&quot;</span>, <span class="hljs-string">&quot;some-value&quot;</span>)
    .getOrCreate()
)

sc = spark.sparkContext

<span class="hljs-keyword">import</span> os

data_path = <span class="hljs-string">&quot;/data/pets.csv&quot;</span>
base_path = os.path.dirname(os.getcwd())
path = base_path + data_path
</code></pre>
<pre><code class="lang-python">pets = spark.read.csv(path, header=<span class="hljs-keyword">True</span>)
pets.toPandas()
</code></pre>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>breed_id</th>
      <th>nickname</th>
      <th>birthday</th>
      <th>age</th>
      <th>color</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>King</td>
      <td>2014-11-22 12:30:31</td>
      <td>5</td>
      <td>brown</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3</td>
      <td>Argus</td>
      <td>2016-11-22 10:05:10</td>
      <td>10</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>Chewie</td>
      <td>2016-11-22 10:05:10</td>
      <td>15</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>Maple</td>
      <td>2018-11-22 10:05:10</td>
      <td>17</td>
      <td>white</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="spark-functions-arent-enough-i-need-my-own">Spark Functions aren&apos;t Enough, I Need my Own!</h3>
<p>What happens when you can&apos;t find functions that can perform what you want? Try looking again &#x1F92A;. But if this is really the case, your last resort can be to implement an <code>udf</code> short for <code>user defined function</code>.</p>
<p>These are functions written in python code that take a subset of columns as the input and returns a new column back. There are multiple steps in creating a <code>udf</code>, we&apos;ll walk through one and decompose it step by step. </p>
<h3 id="option-1-steps">Option 1: Steps</h3>
<pre><code class="lang-python"><span class="hljs-comment"># Step 1: Create your own function</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">uppercase_words</span><span class="hljs-params">(word, cuttoff_length=<span class="hljs-number">2</span>)</span>:</span>
    <span class="hljs-keyword">return</span> word.upper()[:cuttoff_length] <span class="hljs-keyword">if</span> word <span class="hljs-keyword">else</span> <span class="hljs-keyword">None</span>

s = <span class="hljs-string">&apos;Hello World!&apos;</span>
print(s)
print(uppercase_words(s, <span class="hljs-number">20</span>))

<span class="hljs-comment"># Step 2: Register the udf as a spark udf</span>
uppercase_words_udf = F.udf(uppercase_words, T.StringType())

<span class="hljs-comment"># Step 3: Use it!</span>
(
    pets
    .withColumn(<span class="hljs-string">&apos;nickname_uppercase&apos;</span>, uppercase_words_udf(F.col(<span class="hljs-string">&apos;nickname&apos;</span>)))
    .withColumn(<span class="hljs-string">&apos;color_uppercase&apos;</span>, uppercase_words_udf(F.col(<span class="hljs-string">&apos;color&apos;</span>)))
    .withColumn(<span class="hljs-string">&apos;color_uppercase_trimmed&apos;</span>, uppercase_words_udf(F.col(<span class="hljs-string">&apos;color&apos;</span>), F.lit(<span class="hljs-number">3</span>)))
    .toPandas()
)
</code></pre>
<pre><code>Hello World!
HELLO WORLD!
</code></pre><div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>breed_id</th>
      <th>nickname</th>
      <th>birthday</th>
      <th>age</th>
      <th>color</th>
      <th>nickname_uppercase</th>
      <th>color_uppercase</th>
      <th>color_uppercase_trimmed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>King</td>
      <td>2014-11-22 12:30:31</td>
      <td>5</td>
      <td>brown</td>
      <td>KI</td>
      <td>BR</td>
      <td>BRO</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3</td>
      <td>Argus</td>
      <td>2016-11-22 10:05:10</td>
      <td>10</td>
      <td>None</td>
      <td>AR</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>Chewie</td>
      <td>2016-11-22 10:05:10</td>
      <td>15</td>
      <td>None</td>
      <td>CH</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>Maple</td>
      <td>2018-11-22 10:05:10</td>
      <td>17</td>
      <td>white</td>
      <td>MA</td>
      <td>WH</td>
      <td>WHI</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>What Happened?</strong></p>
<p>Although the upper function is defined in the spark <code>fuctions</code> library it still serves as a good example. Let&apos;s breakdown the steps involved:</p>
<ol>
<li>Create the function that you want (<code>uppercase_words</code>), remembering that only <code>spark columnar objects</code> are accepted as input arguments to the function. This means if you want to use other values, you will need to cast it to a column object using <code>F.lit()</code> from the previous sections.</li>
<li>Register the python function as a spark function, and specify the spark return type. The format is like so <code>F.udf(python_function, spark_return_type)</code>.</li>
<li>Now you can use the function!</li>
</ol>
<h3 id="option-2-1-less-step">Option 2: 1 Less Step</h3>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> pyspark.sql.functions <span class="hljs-keyword">import</span> udf

<span class="hljs-comment"># Step 1: Create and register your own function</span>
<span class="hljs-meta">@udf(&apos;string&apos;, &apos;int&apos;)</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">uppercase_words</span><span class="hljs-params">(word, cuttoff_length=<span class="hljs-number">2</span>)</span>:</span>
    <span class="hljs-keyword">return</span> word.upper()[:cuttoff_length] <span class="hljs-keyword">if</span> word <span class="hljs-keyword">else</span> <span class="hljs-keyword">None</span>

<span class="hljs-comment"># Step 2: Use it!</span>
(
    pets
    .withColumn(<span class="hljs-string">&apos;color_uppercase&apos;</span>, uppercase_words_udf(F.col(<span class="hljs-string">&apos;color&apos;</span>)))
    .toPandas()
)
</code></pre>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>breed_id</th>
      <th>nickname</th>
      <th>birthday</th>
      <th>age</th>
      <th>color</th>
      <th>color_uppercase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>King</td>
      <td>2014-11-22 12:30:31</td>
      <td>5</td>
      <td>brown</td>
      <td>BR</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3</td>
      <td>Argus</td>
      <td>2016-11-22 10:05:10</td>
      <td>10</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>Chewie</td>
      <td>2016-11-22 10:05:10</td>
      <td>15</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>Maple</td>
      <td>2018-11-22 10:05:10</td>
      <td>17</td>
      <td>white</td>
      <td>WH</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>What Happened?</strong></p>
<p>The <code>udf</code> function can also be used as a decorator to register your python functions as spark functions. </p>
<p>Where the inputs are the types of the arguments to the <code>udf</code>.</p>
<h3 id="the-ugly-part-of-udfs">The Ugly Part of <code>udf</code>s</h3>
<p><strong>TL;DR</strong> <code>Spark function</code>s are executed on the JVM, while <code>Python UDF</code>s are executed in Python. This will require extra python memory for your spark application (will explain in Chapter 6) and more passing of data between the JVM and Python.</p>
<p>If your function can be performed with the spark <code>functions</code>, you should alway use the spark <code>functions</code>. <code>udf</code>s perform very poorly compared to the spark <code>functions</code>. This is a greate response that encapsulates the reason as to why:</p>
<blockquote>
<p>The main reasons are already enumerated above and can be reduced to a simple fact that Spark DataFrame is natively a JVM structure and standard access methods are implemented by simple calls to Java API. UDF from the other hand are implemented in Python and require moving data back and forth.</p>
<p>While PySpark in general requires data movements between JVM and Python, in case of low level RDD API it typically doesn&apos;t require expensive serde activity. Spark SQL adds additional cost of serialization and serialization as well cost of moving data from and to unsafe representation on JVM. The later one is specific to all UDFs (Python, Scala and Java) but the former one is specific to non-native languages.</p>
<p>Unlike UDFs, Spark SQL functions operate directly on JVM and typically are well integrated with both Catalyst and Tungsten. It means these can be optimized in the execution plan and most of the time can benefit from codgen and other Tungsten optimizations. Moreover these can operate on data in its &quot;native&quot; representation.</p>
<p>So in a sense the problem here is that Python UDF has to bring data to the code while SQL expressions go the other way around.</p>
</blockquote>
<p>source: <a href="https://stackoverflow.com/questions/38296609/spark-functions-vs-udf-performance" target="_blank">https://stackoverflow.com/questions/38296609/spark-functions-vs-udf-performance</a></p>
<h3 id="option-3-pandas-vectorized-udfs">Option 3: Pandas Vectorized <code>UDF</code>s</h3>
<pre><code class="lang-python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html</span>
</code></pre>
<h3 id="summary">Summary</h3>
<ul>
<li>We learnt how to use a python function within spark, called <code>udf</code>s.</li>
<li>We learnt how to pass non-column objects into the function by using knowledge gained from previous chapters.</li>
<li>We learnt about the bad parts of <code>udf</code>s and their performance issues.</li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="Section 2.9 - Filling in Null Values.html" class="navigation navigation-prev " aria-label="Previous page: Section 2.9 - Filling in Null Values">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="Section 2.11  - Unionizing Multiple Dataframes.html" class="navigation navigation-next " aria-label="Next page: Section 2.11  - Unionizing Multiple Dataframes">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Section 2.10 - Spark Functions aren't Enough, I Need my Own!","level":"1.3.15","depth":2,"next":{"title":"Section 2.11  - Unionizing Multiple Dataframes","level":"1.3.16","depth":2,"path":"Chapter 2 - Exploring the Spark APIs/Section 2.11  - Unionizing Multiple Dataframes.md","ref":"Chapter 2 - Exploring the Spark APIs/Section 2.11  - Unionizing Multiple Dataframes.md","articles":[]},"previous":{"title":"Section 2.9 - Filling in Null Values","level":"1.3.14","depth":2,"path":"Chapter 2 - Exploring the Spark APIs/Section 2.9 - Filling in Null Values.md","ref":"Chapter 2 - Exploring the Spark APIs/Section 2.9 - Filling in Null Values.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-sharing","katex@1.1.3","edit-link@2.0.x","github@2.0.x"],"root":"./src","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"edit-link":{"label":"Edit","base":"https://github.com/ericxiao251/spark-syntax/edit/master"},"github":{"url":"https://github.com/ericxiao251/spark-syntax"},"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":14,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"toc":true},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"gitbook":"3.2.x"},"file":{"path":"Chapter 2 - Exploring the Spark APIs/Section 2.10 - Spark Functions aren't Enough, I Need my Own!.md","mtime":"2019-03-21T01:55:34.977Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-03-21T01:55:40.233Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

